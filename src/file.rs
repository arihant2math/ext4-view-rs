// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or
// https://www.apache.org/licenses/LICENSE-2.0> or the MIT license
// <LICENSE-MIT or https://opensource.org/licenses/MIT>, at your
// option. This file may not be copied, modified, or distributed
// except according to those terms.

use crate::block_index::{FileBlockIndex, FsBlockIndex};
use crate::error::Ext4Error;
use crate::extent::Extent;
use crate::inode::Inode;
use crate::iters::AsyncIterator;
use crate::iters::file_blocks::FileBlocks;
use crate::path::Path;
use crate::resolve::FollowSymlinks;
use crate::util::usize_from_u32;
use crate::{Ext4, InodeFlags, file_blocks};
use core::cmp::max;
use core::fmt::{self, Debug, Formatter};
use core::num::NonZeroU32;

/// An open file within an [`Ext4`] filesystem.
pub struct File {
    fs: Ext4,
    inode: Inode,
    file_blocks: FileBlocks,

    /// Current byte offset within the file.
    position: u64,

    /// Current block within the file. This is an absolute block index
    /// within the filesystem.
    ///
    /// If `None`, either the next block needs to be fetched from the
    /// `file_blocks` iterator, or the end of the file has been reached.
    block_index: Option<FsBlockIndex>,
}

impl File {
    /// Open the file at `path`.
    pub(crate) async fn open(
        fs: &Ext4,
        path: Path<'_>,
    ) -> Result<Self, Ext4Error> {
        let inode = fs.path_to_inode(path, FollowSymlinks::All).await?;

        Self::open_inode(fs, inode)
    }

    /// Open `inode`. Note that unlike `File::open`, this allows any
    /// type of `inode` to be opened, including directories and
    /// symlinks. This is used by `Ext4::read_inode_file`.
    pub fn open_inode(fs: &Ext4, inode: Inode) -> Result<Self, Ext4Error> {
        Ok(Self {
            fs: fs.clone(),
            position: 0,
            file_blocks: FileBlocks::new(fs.clone(), &inode)?,
            inode,
            block_index: None,
        })
    }

    /// Access the internal [`Inode`] for this file. This allows for reading metadata etc.
    #[must_use]
    pub fn inode(&self) -> &Inode {
        &self.inode
    }

    /// Mutable access to the internal [`Inode`] for this file. This allows for modifying metadata etc.
    /// Note that changes to the inode will not be persisted until [`Inode::write`] is called.
    pub fn inode_mut(&mut self) -> &mut Inode {
        &mut self.inode
    }

    /// Read bytes from the file into `buf`, returning how many bytes
    /// were read. The number may be smaller than the length of the
    /// input buffer.
    ///
    /// This advances the position of the file by the number of bytes
    /// read, so calling `read_bytes` repeatedly can be used to read the
    /// entire file.
    ///
    /// Returns `Ok(0)` if the end of the file has been reached.
    pub async fn read_bytes(
        &mut self,
        mut buf: &mut [u8],
    ) -> Result<usize, Ext4Error> {
        // Nothing to do if output buffer is empty.
        if buf.is_empty() {
            return Ok(0);
        }

        // Nothing to do if already at the end of the file.
        if self.position >= self.inode.size_in_bytes() {
            return Ok(0);
        }

        // Get the number of bytes remaining in the file, starting from
        // the current `position`.
        //
        // OK to unwrap: just checked that `position` is less than the
        // file size.
        let bytes_remaining = self
            .inode
            .metadata()
            .size_in_bytes
            .checked_sub(self.position)
            .unwrap();

        // If the the number of bytes remaining is less than the output
        // buffer length, shrink the buffer.
        //
        // If the conversion to `usize` fails, the output buffer is
        // definitely not larger than the remaining bytes to read.
        if let Ok(bytes_remaining) = usize::try_from(bytes_remaining) {
            if buf.len() > bytes_remaining {
                buf = &mut buf[..bytes_remaining];
            }
        }

        let block_size = self.fs.0.superblock.block_size();

        // Get the block to read from.
        let block_index = if let Some(block_index) = self.block_index {
            block_index
        } else {
            // OK to unwrap: already checked that the position is not at
            // the end of the file, so there must be at least one more
            // block to read.
            let block_index = self.file_blocks.next().await.unwrap()?;

            self.block_index = Some(block_index);

            block_index
        };

        // Byte offset within the current block.
        //
        // OK to unwrap: block size fits in a `u32`, so an offset within
        // the block will as well.
        let offset_within_block: u32 =
            u32::try_from(self.position % block_size.to_nz_u64()).unwrap();

        // OK to unwrap: `offset_within_block` is always less than or
        // equal to the block length.
        //
        // Note that if this block is at the end of the file, the block
        // may extend past the actual number of bytes in the file. This
        // does not matter because the output buffer's length was
        // already capped earlier against the number of bytes remaining
        // in the file.
        let bytes_remaining_in_block: u32 = block_size
            .to_u32()
            .checked_sub(offset_within_block)
            .unwrap();

        // If the output buffer is larger than the number of bytes
        // remaining in the block, shink the buffer.
        if buf.len() > usize_from_u32(bytes_remaining_in_block) {
            buf = &mut buf[..usize_from_u32(bytes_remaining_in_block)];
        }

        // OK to unwrap: the buffer length has been capped so that it
        // cannot be larger than the block size, and the block size fits
        // in a `u32`.
        let buf_len_u32: u32 = buf.len().try_into().unwrap();

        // Read the block data, or zeros if in a hole.
        if block_index == 0 {
            buf.fill(0);
        } else {
            self.fs
                .read_from_block(block_index, offset_within_block, buf)
                .await?;
        }

        // OK to unwrap: reads don't extend past a block, so this is at
        // most `block_size`, which always fits in a `u32`.
        let new_offset_within_block: u32 =
            offset_within_block.checked_add(buf_len_u32).unwrap();

        // If the end of this block has been reached, clear
        // `self.block_index` so that the next call fetches a new block
        // from the iterator.
        if new_offset_within_block >= block_size {
            self.block_index = None;
        }

        // OK to unwrap: the buffer length is capped such that this
        // calculation is at most the length of the file, which fits in
        // a `u64`.
        self.position =
            self.position.checked_add(u64::from(buf_len_u32)).unwrap();

        Ok(buf.len())
    }

    /// Truncate or extend the file to `new_size` without allocating or deallocating blocks.
    ///
    /// - Shrinking succeeds only if it does not require freeing any blocks (i.e., stays within
    ///   the same last allocated block).
    /// - Growing succeeds only if it does not require allocating new blocks (i.e., the target
    ///   position lies within already allocated blocks or holes are not introduced).
    pub async fn truncate(&mut self, new_size: u64) -> Result<(), Ext4Error> {
        let block_size = self.fs.0.superblock.block_size();

        // Fast path: no change.
        if new_size == self.inode.size_in_bytes() {
            return Ok(());
        }

        async fn block_for_position(
            fs: &Ext4,
            inode: &Inode,
            pos: u64,
        ) -> Result<Option<FsBlockIndex>, Ext4Error> {
            if pos == 0 {
                return Ok(None);
            }
            let block_size = fs.0.superblock.block_size();
            let mut it = FileBlocks::new(fs.clone(), inode)?;
            #[expect(
                clippy::arithmetic_side_effects,
                reason = "We check for pos == 0 above"
            )]
            let num_blocks = (pos - 1) / block_size.to_nz_u64();
            for _ in 0..num_blocks {
                // Advance ignoring value; EOF handled when pos exceeds file mapping.
                it.next().await;
            }
            match it.next().await {
                Some(res) => Ok(Some(res?)),
                None => Ok(Some(0)), // Past mapped blocks -> implies deallocation would be required
            }
        }

        let curr_size = self.inode.size_in_bytes();
        if new_size < curr_size {
            // ensure we do not cross a block boundary in a way that would free blocks.
            let curr_block_num = curr_size / block_size.to_nz_u64();
            let new_block_num = new_size / block_size.to_nz_u64();
            if curr_block_num != new_block_num {
                return Err(Ext4Error::Readonly);
            }
            // Within same block: just update size metadata.
            self.inode.set_size_in_bytes(new_size);
            self.inode.write(&self.fs).await
        } else {
            // Grow: ensure target lies within already allocated blocks (no allocation).
            let target_block =
                block_for_position(&self.fs, &self.inode, new_size).await?;
            // If target_block is Some(0) -> hole or beyond mapping; allocation would be needed.
            if matches!(target_block, Some(0)) {
                return Err(Ext4Error::Readonly);
            }
            // Otherwise permitted: update size metadata only.
            self.inode.set_size_in_bytes(new_size);
            self.inode.write(&self.fs).await
        }
    }

    /// Write bytes from `buf` into the file, returning how many bytes
    /// were written. The number may be smaller than the length of the
    /// input buffer.
    pub async fn write_bytes(
        &mut self,
        buf: &[u8],
    ) -> Result<usize, Ext4Error> {
        // Nothing to do if input buffer is empty.
        if buf.is_empty() {
            return Ok(0);
        }
        let block_size = self.fs.0.superblock.block_size();

        // Special case for writing at position 0 of an empty file
        if self.inode.size_in_bytes() == 0
            && self.position == 0
            && self.inode.flags().contains(InodeFlags::EXTENTS)
        {
            let mut tree = file_blocks::extent_tree::ExtentTree::from_inode(
                self.fs.clone(),
                &self.inode,
            )?;
            tree.extend(
                0,
                NonZeroU32::new(
                    buf.len().div_ceil(block_size.to_usize()) as u32
                )
                .unwrap(),
            )
            .await?;
            for i in 0..buf.len().div_ceil(block_size.to_usize()) as u32 {
                let block_index = tree.get_block(i).await?.unwrap();
                let buf_offset = (i as usize) * block_size.to_usize();
                let to_write = &buf[buf_offset
                    ..(buf_offset + block_size.to_usize()).min(buf.len())];
                self.fs.write_to_block(block_index, 0, &to_write).await?;
            }
            self.inode.set_inline_data(tree.to_bytes());
            self.inode.set_size_in_bytes(buf.len() as u64);
            self.inode.write(&self.fs).await?;
            self.file_blocks = FileBlocks::new(self.fs.clone(), &self.inode)?;
            return Ok(buf.len());
        }

        // Get the block to write to.
        let block_index = if let Some(block_index) = self.block_index {
            block_index
        } else {
            let next = self.file_blocks.next().await;
            match next {
                Some(res) => {
                    let block_index = res?;
                    self.block_index = Some(block_index);
                    block_index
                }
                None => 0,
            }
        };

        // Refuse to write into holes or beyond mapped blocks; scope is only allocated blocks.
        if block_index == 0 {
            return Err(Ext4Error::Readonly);
        }

        // Offset within the current block.
        let offset_within_block: u32 =
            u32::try_from(self.position % block_size.to_nz_u64()).unwrap();

        // Cap write to remaining bytes in this block.
        let bytes_remaining_in_block: u32 = block_size
            .to_u32()
            .checked_sub(offset_within_block)
            .unwrap();
        let mut write_len = buf.len();
        if write_len > usize_from_u32(bytes_remaining_in_block) {
            write_len = usize_from_u32(bytes_remaining_in_block);
        }

        // Perform the write for the capped portion.
        let to_write = &buf[..write_len];
        self.fs
            .write_to_block(block_index, offset_within_block, to_write)
            .await?;

        // Update position and block iterator state.
        let new_offset_within_block: u32 = offset_within_block
            .checked_add(u32::try_from(write_len).unwrap())
            .unwrap();
        if new_offset_within_block >= block_size {
            // Move to next block on subsequent calls.
            self.block_index = None;
        }
        let new_position = self
            .position
            .checked_add(u64::try_from(write_len).unwrap())
            .unwrap();
        self.position = new_position;

        // If we extended past previous EOF, update inode size without allocating.
        if new_position > self.inode.size_in_bytes() {
            self.inode.set_size_in_bytes(new_position);
            // Persist the inode metadata update.
            self.inode.write(&self.fs).await?;
        }

        Ok(write_len)
    }

    /// Current position within the file.
    #[must_use]
    pub fn position(&self) -> u64 {
        self.position
    }

    /// Seek from the start of the file to `position`.
    ///
    /// Seeking past the end of the file is allowed.
    pub async fn seek_to(&mut self, position: u64) -> Result<(), Ext4Error> {
        // Reset iteration.
        self.file_blocks = FileBlocks::new(self.fs.clone(), &self.inode)?;
        self.block_index = None;

        // Advance the block iterator by the number of whole blocks in
        // `position`.
        let num_blocks =
            position / self.fs.0.superblock.block_size().to_nz_u64();
        for _ in 0..num_blocks {
            self.file_blocks.next().await;
        }

        self.position = position;

        Ok(())
    }

    /// Consume the `File`, returning the underlying `Inode`.
    #[must_use]
    pub fn into_inode(self) -> Inode {
        self.inode
    }
}

impl Debug for File {
    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {
        f.debug_struct("File")
            // Just show the index from `self.inode`, the full `Inode`
            // output is verbose.
            .field("inode", &self.inode.index)
            .field("position", &self.position)
            // Don't show all fields, as that would make the output less
            // readable.
            .finish_non_exhaustive()
    }
}

/// Write `buf` into `inode` starting at `offset`, returning how many bytes were written.
/// The number may be smaller than the length of the input buffer if the write is only partially successful (e.g., due to lack of space).
pub async fn write_at(
    ext4: &Ext4,
    inode: &mut Inode,
    buf: &[u8],
    offset: u64,
) -> Result<usize, Ext4Error> {
    fn blocks_needed_for_bytes(
        offset_in_block: usize,
        bytes_remaining: usize,
        block_size: usize,
    ) -> usize {
        // Compute how many blocks are needed to write bytes_remaining starting at offset_in_block within the first block.
        if offset_in_block >= block_size {
            return 0; // Invalid offset, but treat as needing 0 blocks to avoid overflow
        }
        let first_block_capacity = block_size - offset_in_block;
        if bytes_remaining <= first_block_capacity {
            1
        } else {
            1 + (bytes_remaining - first_block_capacity + block_size - 1)
                / block_size
        }
    }

    fn bytes_for_blocks(
        num_blocks: usize,
        offset_in_block: usize,
        block_size: usize,
    ) -> usize {
        // Compute how many bytes correspond to num_blocks starting at offset_in_block.
        if num_blocks == 0 {
            return 0;
        }
        let first_block_capacity = block_size - offset_in_block;
        if num_blocks == 1 {
            return first_block_capacity.min(block_size);
        }
        first_block_capacity + (num_blocks - 1) * block_size
    }

    async fn write_into_mapped_initialized_extent(
        ext4: &Ext4,
        inode: &Inode,
        extent: &Extent,
        offset_in_extent: usize,
        run_blocks: usize,
        buf: &[u8],
        offset_in_block: usize,
        block_size: usize,
    ) -> Result<usize, Ext4Error> {
        // For an initialized extent, we can directly write to the blocks for the full-block portion.
        // For partial blocks at the boundaries, we need to read-modify-write to preserve existing data.
        // This helper should handle both cases and return the number of bytes written.
        unimplemented!()
    }

    async fn write_into_uninitialized_extent(
        ext4: &Ext4,
        inode: &Inode,
        extent: &Extent,
        offset_in_extent: usize,
        run_blocks: usize,
        buf: &[u8],
        offset_in_block: usize,
        block_size: usize,
    ) -> Result<usize, Ext4Error> {
        // For an uninitialized (unwritten) extent, we need to allocate blocks and mark them initialized.
        // For full-blocks, we can directly write and then flip to initialized.
        // For partial blocks, we must zero the unwritten parts to preserve the semantics of uninitialized extents.
        // This helper should handle both cases and return the number of bytes written.
        unimplemented!()
    }

    fn bytes_consumed_for_blocks(
        num_blocks: usize,
        offset_in_block: usize,
        block_size: usize,
    ) -> usize {
        // Compute how many bytes are consumed for writing num_blocks starting at offset_in_block.
        if num_blocks == 0 {
            return 0;
        }
        let first_block_capacity = block_size - offset_in_block;
        if num_blocks == 1 {
            return first_block_capacity.min(block_size);
        }
        first_block_capacity + (num_blocks - 1) * block_size
    }

    async fn write_into_newly_allocated_extent(
        ext4: &Ext4,
        inode: &Inode,
        extent: &Extent,
        offset_in_block: usize,
        buf: &[u8],
        block_size: usize,
    ) -> Result<usize, Ext4Error> {
        // Contract:
        // - `extent` describes newly allocated blocks (no prior file data).
        // - We must write `buf` starting at `offset_in_block` within the first block.
        // - Any bytes in the allocated blocks not covered by `buf` must be zeroed, so
        //   we don't expose stale disk contents.
        // - Returns the number of bytes from `buf` written.

        if buf.is_empty() {
            return Ok(0);
        }
        if offset_in_block >= block_size {
            return Ok(0);
        }

        // How many blocks from this extent are needed to store `buf` starting at
        // `offset_in_block` in the first block.
        let first_block_capacity = block_size - offset_in_block;
        let needed_blocks = if buf.len() <= first_block_capacity {
            1usize
        } else {
            1usize + (buf.len() - first_block_capacity).div_ceil(block_size)
        };

        // Caller should only pass a slice that fits in the allocated extent, but be
        // defensive. (Also handles weird zero-length extents.)
        let extent_blocks = usize::from(extent.num_blocks);
        let blocks_to_write = core::cmp::min(needed_blocks, extent_blocks);
        if blocks_to_write == 0 {
            return Ok(0);
        }

        let mut written = 0usize;

        for i in 0..blocks_to_write {
            // Filesystem block corresponding to the i'th block in this extent.
            #[expect(
                clippy::arithmetic_side_effects,
                reason = "Extent start + offset stays within u64 for valid filesystems"
            )]
            let fs_block = extent.start_block + i as u64;

            let (block_offset, capacity) = if i == 0 {
                (offset_in_block, block_size - offset_in_block)
            } else {
                (0usize, block_size)
            };

            // Bytes from `buf` that go into this block.
            let remaining = buf.len().saturating_sub(written);
            let take = core::cmp::min(remaining, capacity);
            if take == 0 {
                break;
            }

            let chunk = &buf[written..written + take];

            // If this chunk doesn't fill the entire block from offset 0..block_size,
            // we must write a full block with zeros everywhere else.
            let is_full_block_write = block_offset == 0 && take == block_size;

            if is_full_block_write {
                ext4.write_to_block(fs_block, 0, chunk).await?;
            } else {
                // Zero-fill and place the payload at block_offset.
                let mut block_buf = alloc::vec![0u8; block_size];
                block_buf[block_offset..block_offset + take]
                    .copy_from_slice(chunk);
                ext4.write_to_block(fs_block, 0, &block_buf).await?;
            }

            written += take;
        }

        Ok(written)
    }

    let block_size = ext4.0.superblock.block_size().to_usize();
    if buf.is_empty() {
        return Ok(0);
    }

    let start_block =
        FileBlockIndex::try_from(offset / block_size as u64).unwrap();
    let mut start_offset_in_block = (offset % block_size as u64) as usize;
    let mut bytes_remaining = buf.len();
    let mut buf_pos = 0usize;
    let mut current_block = start_block;
    let mut total_written = 0usize;
    let mut extent_tree =
        file_blocks::extent_tree::ExtentTree::from_inode(ext4.clone(), inode)?;

    while bytes_remaining > 0 {
        let opt_extent = extent_tree.find_extent(current_block).await?;

        match opt_extent {
            Some(extent) => {
                // extent covers a range of file blocks
                let extent_block_start = extent.block_within_file;
                let extent_block_len = extent.num_blocks as u64;
                let offset_in_extent =
                    (current_block - extent_block_start) as u64;
                // number of blocks available in this extent starting at current_block
                let avail_blocks_in_extent =
                    (extent_block_len - offset_in_extent) as usize;

                // determine how many bytes we can handle within this extent in a single run:
                // convert bytes_remaining + start_offset_in_block... but simpler: compute how many file-blocks
                // we can process here: `run_blocks = min(avail_blocks_in_extent, blocks_covered_by_bytes_remaining)`
                let max_blocks_needed = blocks_needed_for_bytes(
                    start_offset_in_block,
                    bytes_remaining,
                    block_size,
                );
                let run_blocks =
                    core::cmp::min(avail_blocks_in_extent, max_blocks_needed);

                // prepare to write run_blocks starting at current_block
                if extent.is_initialized {
                    // case A: initialized extent -> RMW for partial block at boundaries, direct write for full blocks
                    total_written += write_into_mapped_initialized_extent(
                        ext4,
                        inode,
                        &extent,
                        offset_in_extent as usize,
                        run_blocks,
                        &buf[buf_pos
                            ..buf_pos
                                + bytes_for_blocks(
                                    run_blocks,
                                    start_offset_in_block,
                                    block_size,
                                )],
                        start_offset_in_block,
                        block_size,
                    )
                    .await?;
                } else {
                    // case B: uninitialized (unwritten) extent
                    // For full-blocks: we can directly write blocks and then flip to initialized.
                    // For partial blocks: we must zero the rest of the block(s) we don't overwrite.
                    total_written += write_into_uninitialized_extent(
                        ext4,
                        inode,
                        &extent,
                        offset_in_extent as usize,
                        run_blocks,
                        &buf[buf_pos
                            ..buf_pos
                                + bytes_for_blocks(
                                    run_blocks,
                                    start_offset_in_block,
                                    block_size,
                                )],
                        start_offset_in_block,
                        block_size,
                    )
                    .await?;
                    // this helper must split the extent and mark the written blocks initialized
                }

                // advance
                let advanced_bytes = bytes_consumed_for_blocks(
                    run_blocks,
                    start_offset_in_block,
                    block_size,
                );
                bytes_remaining -= advanced_bytes;
                buf_pos += advanced_bytes;
                current_block =
                    current_block + FileBlockIndex::from(run_blocks as u32);
                // after first block, start_offset_in_block becomes 0 for subsequent loops
                start_offset_in_block = 0;
            }
            None => {
                // case C: hole -> allocate new blocks, create initialized extents and write
                // Decide how many blocks to allocate: prefer as many contiguous full-blocks as possible.
                // Map bytes_remaining -> needed_blocks (including first partial block)
                let needed_blocks = blocks_needed_for_bytes(
                    start_offset_in_block,
                    bytes_remaining,
                    block_size,
                );

                // Try to allocate needed_blocks. If allocation fails for full amount, try smaller (but >0).
                let mut tried_blocks = needed_blocks;
                let start_fs_block = loop {
                    match ext4
                        .alloc_contiguous_blocks(
                            inode.index,
                            NonZeroU32::new(tried_blocks as u32).unwrap(),
                        )
                        .await
                    {
                        Ok(start_fs) => break start_fs,
                        Err(_) => {
                            if tried_blocks == 0 {
                                return Ok(total_written);
                            }
                            tried_blocks = tried_blocks / 2; // or tried_blocks - 1
                            if tried_blocks == 0 {
                                return Ok(total_written);
                            }
                        }
                    }
                };
                // Insert extent: file-blocks [current_block, current_block + tried_blocks) -> FS blocks [start_fs_block, ...]
                let new_extent = Extent::new(
                    current_block,
                    start_fs_block,
                    tried_blocks as u16,
                );
                extent_tree.insert_extent(new_extent).await?;
                // Write data into the newly allocated blocks (same logic as initialized extents except we don't need to read old content)
                // If first or last block is partial, zero the unwritten parts.
                let want_bytes = bytes_for_blocks(
                    tried_blocks,
                    start_offset_in_block,
                    block_size,
                );
                let have_bytes = bytes_remaining;
                let slice_len = core::cmp::min(want_bytes, have_bytes);
                total_written += write_into_newly_allocated_extent(
                    ext4,
                    inode,
                    &new_extent,
                    start_offset_in_block,
                    &buf[buf_pos..buf_pos + slice_len],
                    block_size,
                )
                .await?;

                // advance variables
                // We must advance based on how many bytes we actually wrote into the
                // newly allocated blocks. Advancing by the theoretical block capacity
                // can underflow `bytes_remaining` when `slice_len` is smaller.
                let advanced_bytes = slice_len;
                bytes_remaining -= advanced_bytes;
                buf_pos += advanced_bytes;
                current_block = FileBlockIndex::try_from(
                    (offset + (buf_pos as u64)) / (block_size as u64),
                )
                .unwrap();
                start_offset_in_block = ((offset + (buf_pos as u64))
                    % (block_size as u64))
                    as usize;
            }
        }
        // Optional: after each change, try merging adjacent extents to keep tree compact
        // (Currently unimplemented; safe to skip.)
        extent_tree.try_merge_adjacent(current_block).await?;
    }

    inode.set_size_in_bytes(max(
        inode.size_in_bytes(),
        offset + (total_written as u64),
    ));
    inode.set_inline_data(extent_tree.to_bytes());
    inode.write(ext4).await?;

    Ok(total_written)
}
